\chapter{Radar Fundamentals: Theoretical Background}
This section provides a foundation for understanding the principles and methodologies underpinning FMCW MIMO radar imaging.
We begin by elucidating the signal model employed in FMCW radar systems, 
elucidating the distinctions between single-channel and MIMO configurations.
Subsequently, we delve into the intricacies of image reconstruction techniques,
exploring both the Discrete Fourier Transform (DFT) approach and the proposed backprojection algorithm.

- Pre-cite: Definitions from Balanis & IEEE Standard Definitions
- Window Functions
\section{Antenna Fundamentals}

The fundamental working principle of radars is to transmit an electromagnetic wave,
receive a reflected version of the same wave, 
and to estimate the local scenery based on how much the signal has changed between transmission and reception.
Antennas are the key building block to enable said transmission and reception.
They determine the directional characteristics of signals,
influencing radar coverage, resolution, and sensitivity.
Therefore, a brief overview of both the physical foundation 
and the technical description of antennas is given in the following.

\subsection{Physical Background}
 
- electromagnetic radiation


The space surrounding a transmit antenna is typically divided into three distinct regions,
based on the antennas maximum overall dimension $D$ and the wavelength $\lambda$ of the propagating wave: 
\begin{itemize}
    \item \emph{reactive near-field region}.
    In this region the interaction between the antenna and its surrounding medium takes place.
    Energy oscillates between being stored in the electromagnetic field in the medium 
    and the electrical charge distribution of the antenna.
    
    \item \emph{radiating near-field region}.
    Starting from a distance of $0.62\sqrt{D^3/lambda}$ (or $\frac{\lambda}{2\pi}$ unless $D\gg\lambda$),
    the field is made up predominantly of radiation fields emitted by the antenna.
    In this region, the angular distribution of the field depends on the distance of the antenna.

    \item \emph{radiating far-field region}.
    Above a distance of $d_F = 2D^2/\lambda$,
    the angular distribution of the field stops depending on the distance of the antenna,
    rendering them essentially transverse.
\end{itemize}

The radiating near-- and far-field regions are sometimes called Fresnel region and Frauenhofer region, respectively.
These terms are based on an optical analogy for antennas focused at infinity.

While notable differences exist among the zones,
there are no sudden shifts in the field configurations as one transitions between them. 

\subsection{Antenna Parameters}
In the following, a set of key parameters is defined that are used to describe an antenna's performance.
They are adapted from the definitions in [IEEE something].

The \emph{radiation pattern} or \emph{antenna pattern} 
describes the radiation properties of an antenna as a function of spatial coordinates.
According to [IEEE], ``[the] quantities that are most often used to characterize the radiation from an antenna
are proportional to or equal to power flux density,
radiation intensity, directivity, phase, polarization, and field strength.''

For directive antennas, radiation patterns usually form so-called \emph{lobes}, 
which are the areas between zero crossings of the pattern. 
The lobe in the direction of maximum gain is called the \emph{major lobe},
while all others are called \emph{minor lobes}.
Minor lobes can be further broken down into \emph{side lobes} and \emph{back lobes},
where the back lobe faces in the exact opposite direction of the main lobe,
and \emph{side lobes} usually directly next to it.
[Figure asdf shows a qualitative example of a radiation pattern,
designating one of each type of lobe].

An important measure of a radiation pattern is its half-power beamwidth (HPBW).
It corresponds to the angle between the two points 
in a radiation pattern's main lobe that are exactly half the power (\SI{-3}{\dB})
below the main lobe's maximum. Other measures include the quarter-power beamwidth
(\SI{-6}{\dB} from the peak), and the first-null beamwidth (FNBW) which measures the width of the entire main lobe.

The \emph{radiation power density} is derived from electromagnetic field properties,
namely the time average Poynting vector.
Assuming time-harmonic electric and magnetic fields with 
\begin{align}
    \vec H(\vec r, t) &= \mathfrak{Re}\{\vec \underline{H}(\vec{r}) e^j\omega t\} \text{ and } \\
    \vec E(\vec r, t) &= \mathfrak{Re}\{\vec \underline{E}(\vec{r}) e^j\omega t\},
\end{align}
the time-average Poynting vector becomes
\begin{align}
    \vec S_{avg} = \frac{1}{2} \mathfrak{Re}\{ \vec\underline E \times \vec\underline H^* \}.
\end{align}

Under far-field conditions,
the ``power radiated from an antenna per unit solid angle'' can be assumed to be independent of distance.
That motivates defining this quantity as the \emph{radiation intensity}
It can be expressed in terms of the radial component of the radiation power density:
\begin{align}
    U = r^2 \hat e_r \cdot \vec S_{avg},
\end{align}
where $\hat e_r$ is the unit vector in radial direction.

An idealized example, often used as a theoretical reference, is the isotropic lossless radiator, 
which transforms all input power $P_{in}$ into a planar spherical wave propagating out.
Its radiation power density is simply
\begin{align}
    \vec S_{0} = \frac{P_{in}}{4\pi r^2} \hat e_r,
\end{align}
making its radiation intensity
\begin{align}
    U_{0} = \frac{P_{in}}{4\pi}.
\end{align}

Another important quantity is called the antenna gain.
The \emph{absolute gain} refers to the ratio of an antenna's radiation intensity
to that of the isotropic lossless radiator receiving the same input power:
\begin{align}
    G_{abs}(\theta, \phi) = \frac{U(\theta, \phi)}{U_0} = \frac{4\pi}{P_{in}} U(\theta, \phi)
\end{align} 
The  \emph{relative gain} refers to the ratio of an antenna's radiation intensity
to that of another antenna that is not necessarily an isotropic lossless radiator:
\begin{align}
    G_{rel}(\theta, \phi) = \frac{U(\theta, \phi)}{U_ref(\theta, \phi)} = \frac{4\pi}{P_{in}} U(\theta, \phi)
\end{align} 
A gain pattern $G(\theta, \phi)$ can further be subdivided into its maximum $G$ 
and a function $c(\theta, \phi)$ called its \emph{normalized gain pattern}:
\begin{align}
    G(\theta, \phi) = G \cdot c(\theta, \phi)
\end{align}
with 
\begin{align*}
    G = \text{max }G, g(\theta, \phi) = \frac{G(\theta, \phi)}{G}, |g| \in [0,1]
\end{align*}



\subsection{Antenna Arrays}

The radiation patterns of single antennas are usually rather wide.
To make it more narrow, the dimensions of the antenna have to be increased [balanis p. 283].
This can be accomplished by using multiple copies of the same antenna arranged into a structure called an \emph{array}.
By constructive and destructive interference between the fields generated by the array's elements,
the arrays resulting radiation pattern can be increased in the desired direction and decreased in all others.
Beside the radiation pattern of the individual antennas, 
the geometric makeup of the array is chiefly important to the array's radiation pattern.
The array's relative gain, expressed with reference to a single array element,
is called the \emph{array factor}.

An important variant is the \emph{uniform linear array (ULA)} ,
which consists of $N$
``identical elements all of identical magnitude and each with a progressive phase''[balanis p. 290 ff.].
The array factor can be expressed as a function of the direction $\theta$,
the phase offset between elements $\delta \varphi$, the distance between elements $d$
and the wavenumber $k=\omega/c$:
\begin{align}
    \text{AF} &= \dfrac{\text{sin}\left(\frac{N}{2}\psi\right)}{\text{sin}\left(\frac{1}{2}\psi\right)}
    \simeq \text{sinc}\left(\frac{N}{2}\psi\right) \text{ for } \psi \ll 1 \\
    \text{with } \psi &= (kd\text{cos}\theta + \delta\varphi)
\end{align}
Note that the array factor has an additional factor of $e^j\psi(N-1)/2$
if the reference element is not in the center of the array.

Other array configurations include non-uniform linear arrays as well as planar and circular arrays. 

\section{Signal Model}
Understanding the signal model is fundamental to grasp the operation and capabilities of FMCW MIMO radar systems.
In this section, we delve into the intricacies of the signal model,
beginning with an exploration of Single Channel Frequency Modulated Continuous Wave (FMCW) radar systems.
We clarify the key principles governing their signal generation and processing,
laying the groundwork for a comprehensive understanding of radar imaging techniques.
Then, we extend our analysis to encompass Multiple Input Multiple Output (MIMO) FMCW radar systems,
highlighting the unique characteristics and complexities associated with their signal model.

\subsection{Single Channel FMCW}
A single channel consists of a transmit antenna and a receive antenna.
The transmit antenna sends a so-called chirp of duration $T_{chirp}$,
which is a sinusoid with linearly increasing frequency.
The signal $x_{TX}(t)$ send by the transmit antenna is reflected by an ideal point scatterer at position $\vec r_S$
and then received at the receive antenna as $x_{RX}(t)$.
The propagation delay $\tau$ can be calculated using the speed of light $c_0$,
and the locations of the receive and transmit antennas $\vec r_{RX}$ and $\vec r_{TX}$:
\begin{align}
    \tau = \frac{\| \vec r_{TX} - \vec r_S \|+\| \vec r_{RX} - \vec r_S \|}{c_0}
\end{align}
Using a complex representation for the in-phase and quadrature components of the signal,
the transmit and receive signal can be formulated for $t \in [0, T_{chirp}]$:
\begin{align}
    x_{TX}(t) & = A_0 e^{j(\omega_0t + \frac{1}{2}\dot \omega t^2 + \phi_0)} \label{eqn:x_TX} \\
    x_{RX}(t) & = A(\vec r_S) x_{TX}(t-\tau)                                 \label{eqn:x_RX} \\
\end{align}
The received signal is then mixed with a copy of the transmitted signal (\ref{eqn:x_TX}) and a low-pass filter is applied.
The resulting signal $y(t)$ is called \textit{intermittent frequency} signal.
\begin{align}
    y(t) & = \text{LP} \left\{ x_{RX}(t) \cdot x_{TX}(t) \right\}         \\
         & = \text{LP} \left\{
    A_0 e^{j(\omega_0t + \frac{1}{2}\dot \omega t^2) }
    \cdot A(\vec r_S) A_0 e^{j(\omega_0(t-\tau(\vec r)) + \frac{1}{2}\dot \omega (t-\tau(\vec r))^2) }
    \right\}                                                              \\
         & = A_0^2A(\vec r_S)
    e^{j(\frac{1}{2}\dot\omega\tau^2(\vec r_S)- \omega_0\tau)}
    \cdot  \text{LP} \left\{
    e^{j(2\omega_0 t + \frac{1}{2}\dot\omega t^2 - \dot\omega\tau t)}
    \right\}                                                \label{eqn:G} \\
         & \approx G(\vec r_S) e^{-j\dot\omega\tau t} \label{eqn:y_IF}
\end{align}
The fact that the IF-signal contains all the information
-- i.e. the IF signal's frequency directly corresponds to the target's distance --
explains the main advantage of this technology.
The carrier frequency can be orders of magnitude higher than the intermittent frequency,
which drastically reduces the requirements for the subsequent signal processing,
while retaining the improved resolution due to the smaller wavelenghts of the carrier frequency.

FIND QUOTE:"GHz resolution for MHz processing"

To locate a target in the cross-range dimensions,
a single-channel FMCW-radar can be used to scan in multiple directions,
by either rotating the antennas, redirecting their beam with rotating mirrors, or with beamforming antenna arrays.
In any case, this requires highly directive antennas and also increases size, weight and cost of a radar sensor.


\subsection{Multiplexing Techniques}
Multiple-input multiple-output radar benefits from increased diversity and signal power.
If $N_{TX}$ transmit antennas and $N_{TX}$ receive antennas are employed, $K=N_{TX} \cdot N_{RX}$ different signals can be extracted.
To differentiate the signals from each other, a multiplexing technique has to be chosen.
Options include time division multiplex, frequency division multiplex and code division multiplex.

In TDM, multiple access is achieved by the transmit antennas all send one after another,
while all receive antennas receive simultaneously.
In FDM, simultaneous transmission is made possible by subdividing the bandwidth and assigning a different frequency range to each antenna.
That means that TDM allows for higher bandwidths for each transmission, while FDM allows higher transmission durations.

In CDM, both simultaneous transmission and use of the entire bandwidth is made possible by using a different waveform to each channel.
However, processing at the carrier frequency is required to differentiate the signals from another, as opposed to TDM and FMD,
where all processing can be done at the intermittent frequency range.

Depending on the application, a compromise has to be found between the advantages and drawbacks of each method.
There are also methods available that combine aspects of these three basic paradigms, such as OFDM and Hadamard-Coding.[citation needed] \\

\subsection{Virtual Antenna Arrays}
An important concept in analizing MIMO arrays is that of the \emph{virtual antenna array}:
in a nutshell, the idea is to express the $N_{TX} \times N_{RX}$ MIMO array as an equivalent $1\times K$ SIMO array.
The procedure to construct the corresponding virtual array for a given MIMO array is as follows:

The transmit antenna associated with channel $k=0$ is placed in the origin of the virtual array's coordinate system.
Then, $K$ receive antennas are placed such that the displacement between them and the transmit antenna
is the same as it was between the original MIMO array's corresponds transmit and receive antenna.
It is possible for virtual antennas to overlap. 
As we will see later, the input signal under far-field conditions only depends 
on the relative displacement between the Tx- and Rx-antennas of a channel, and not their absolute positions.

An example MIMO array and its corresponding virtual array can be seen in figures a and b, respectively.
The numbering convention for channel index $k$ corresponding to transmit antenna $i$ and receive antenna $j$,
that is also used throughout the thesis is as follows:
\begin{align}
    k = N_{Tx}i + j
\end{align}
In our example, the virtual transmit antenna with $k=5$ corresponds to $(i,j)=(1,2)$. \\


Once the received signals are demultiplexed, the ideal receive signal for antenna pair $k \in \{0,1,...K-1\}$:
\begin{align}
    y_k(t) & = C_k(\vec r_S)e^{-j\dot\omega\tau_k(\vec r_S)t} \label{eqn:ideal_scatterer}
\end{align}
The factor $C_k(\vec r_S)$ is called \emph{channel gain}
and summarizes multiple factors multiple factors in
Friis transmission equation and the radar range equation [balanis p.]. Namely,
\begin{align}
    C_k() 
\end{align}

In reality, the scene can consist of multiple and expansive scatterers,
that reflect the transmitted signals at different intensities.
which is summarized as a locational reflectivity $F_k(\vec r)$.
\footnote{
    The index $k$ is introduced here to take obstructed visibility into account:
    from the point of view of one channel, two scatterers may be visible simultaneously,
    while from the point of view of another, one might obstruct the other's visiblity.
}
Also, interference and electric noise may be present in each channel,
which we summarize as $n_k(t)$.
Thus, the overall IF-signal is:
\begin{align}
    y_k(t) & = \iiint F_k(\vec r)G_k(\vec r) e^{-j\dot\omega\tau_k(\vec r)t} \;d\vec r + n_k(t) \\
\end{align}
After sampling the signal at sampling intervals $T_s$ such the sampling frequency $f_s = \frac{1}{T_s}$
is sufficiently high: ${2f_s > \frac{1}{2\pi}(\omega_0 + \dot \omega T_{chirp})}$, and with $M$ samples such that $MT_s < T_{chirp}$,
the sampled IF-signal can be defined as:
\begin{align}
    y_k[m] = y_k(t=mT_s), \text{for}\;m \in \{0,1,..M-1\}
\end{align}

\section{Image Reconstruction}
Image reconstruction is an inverse problem where the locational reflectivity of the scene $F(\vec r)$
has to be estimated from the received signals $y_k[m]$.
Multiple approaches are available; in the following, three will be presented.

\subsection{Discrete Fourier Transform}
\label{ssec:dft_imaging_theory}
The discrete fourier transform can be implemented with high efficiency,
and many CPUs even include silicone-based implementations [citation needed].
In this approach, the DFT is applied over three dimensions of the input signal,
obtaining a discrete output signal in spherical coordinates whose amplitude is an estimate of the locational reflectivity.

For each input channel, the range of a target can be estimated by applying the DFT over time.
The resulting spectrum's peak corresponds to the target:
\begin{align}
    \mathcal{F}_m\{y_k[m]\}(\Omega) & = \sum_{m=0}^{M-1} e^{-j2\pi\frac{m\Omega}{M}} y_k[m]                            \\
                                    & = G_k(\vec r_S) \delta(\Omega-\dot \omega \tau_k(\vec r_S)T_s) \label{eqn:y_fft}
\end{align}


In order to understand how information on the direction of a target can be extracted from the channel data,
we consider an ideal $1 \times K$ horizontal uniform linear array (\textit{ULA}) where the spacing is exactly $d=\frac{\lambda_0}{2}$, with $\lambda_0 = \frac{c_0}{f_0}$.
The antennas are located at $\vec r_{TX}= \vec 0$ and $\vec r_{RX,k}=(kd,0,0)^T$.
A scatterer located at  $\vec r_S = (r_S\sin\theta_S, r_{S}\cos\theta_S , 0)^T$  reflects the transmitted radar waves with an intensity of $A_S$.
Then, their runtime across the array is:

\begin{align}
    \tau_k & =\frac{1}{c_0} \left( \| \vec r_{TX} - \vec r_S \|+\| \vec r_{RX} - \vec r_S \| \right) \\
\end{align}

In far-field conditions, the target is far enough ($r \gg K d$) away for the reflected wavefronts to be planar.
That means that the runtime can then be approximated as such:

\begin{align}
    \tau_k \approx 2r_S + kd\sin\theta_S
\end{align}
In equation \ref{eqn:G} it can be seen that the locational gain $G(\vec r)$ contains a phase shift depending on the runtime of the waves:
\begin{align}
    G_k(\vec r) & = A_S A_k(\vec r) e^{j(\frac{1}{2}\dot\omega\tau_k^2- \omega_0\tau_k)} \\
                & \approx A_S A_k(\vec r) e^{-j\omega_0\tau_k}
\end{align}
Assuming the attenuation along the path is channel-independent, the signals can all be considered copies of each other:
\begin{align}
    y_k(t)             & = A_S A_k(\vec r) e^{-j\omega_0\tau_k} e^{-j\dot\omega\tau_k t}      \\
                       & = A_S A_k(\vec r) e^{-j \frac{\omega_0}{c_0}(2r_S + kd\sin\theta_S)}
    e^{-j\frac{\dot\omega}{c_0}(2r_S +  \overbrace{kd\sin\theta_S}^{\text{$\ll 2r_S$}} )t}    \\
                       & = A_S A_0(\vec r) e^{-j \frac{\omega_0}{c_0}2r_S }
    e^{-j\frac{\dot\omega}{c_0}2r_St} e^{-j \frac{\omega_0}{c_0}kd\sin\theta_S}               \\
                       & = y_0(t) e^{-j \frac{\omega_0}{c_0}kd\sin\theta_S}                   \\
    \Rightarrow y_k[m] & = y_k(t=mT_S) = y_0[m]e^{-j \frac{\omega_0}{c_0}kd\sin\theta_S}
\end{align}
Applying the DFT accross the ULA yields:
\begin{align}
    \mathcal{F}_k\{y_k[m]\}(\Omega) & = \mathcal{F}_k\{y_0[m]e^{-j \frac{\omega_0}{c_0}kd\sin\theta_S}\}(\Omega)      \\
                                    & = y_0[m] \cdot \delta \left(\Omega -\frac{\omega_0}{c_0}(d\sin\theta_S) \right) \\
                                    & = y_0[m] \cdot \delta \left(\Omega - \pi\sin\theta_S \right)                    \\
\end{align}

The azimuth angle $\theta_S$ can be extracted from the signal supplied by a horizontal ULA.
Analogously, the elevation angle $\phi_S$ can be obtained with a vertical ULA.
If a $1\times K$ virtual array is used, where the $K$ receive antennas form a uniformly spaced grid,
successive DFTs across the rows and columns of this grid yield two dimensions. \\


Overall, a 3D image in range, azimuth, and elevation is generated
by calculating the DFT over time, and the DFTs over the rows and columns of the virtual array.
For this to work, the scatterer needs to be distant enough for the wavefronts to be planar,
and the virtual array's grid needs to be uniformly spaced with $d=\lambda_0/2$ spacing.

\subsection{Backprojection}
\label{ssec:bp_imaging_theory}
Compared to the DFT-based approach, backprojection takes fewer approximations and requirements on the array to work,
while theoretically using a similar amount of computation.
The approach works by correlating the input signal $y_k[m]$
to the theoretical signal $s_k[m, \vec r]$ of an ideal scatterer at different locations.
The mean correlation of all channels to the theoretical signal is then used as an estimate for the locational reflectivity:
\begin{align}
    \hat F(\vec r) & = \frac{1}{K} \sum_{k=0}^{K-1} s_k[m, \vec r] \star y_k[m]             \\
                   & = \frac{1}{K}\sum_{k=0}^{K-1}\sum_{m=0}^{M} s_k^\ast[m, \vec r] y_k[m]
\end{align}
Using the signal model from (\ref*{eqn:ideal_scatterer}) yields:
\begin{align}
    \hat F(\vec r) & = \frac{1}{K}\sum_{k=0}^{K-1}\sum_{m=0}^{M}
    G_k^\ast(\vec r)e^{+j\dot\omega\tau_k(\vec r_S)mT_s} y_k[m]
\end{align}

To reduce the computational intensity of this algorithm,
calculating the inner sum (over $m$) can be rewritten as an inverse discrete fourier transform (IDFT):

\begin{align}
    \hat F(\vec r) & = \frac{1}{K}\sum_{k=0}^{K-1}G_k^\ast(\vec r)
    \sum_{m=0}^{M} e^{+j\dot\omega\tau_k(\vec r_S)mT_s} y_k[m]     \\
                   & = \frac{1}{K}\sum_{k=0}^{K-1}G_k^\ast(\vec r)
    \sum_{m=0}^{M} e^{j\Omega m} y_k[m]
    \Big|_{\Omega=\dot\omega\tau_k(\vec r_S)T_s}                   \\
                   & = \frac{1}{K}\sum_{k=0}^{K-1}G_k^\ast(\vec r)
    \mathcal{F}_m^{-1} \left\{ y_k[m]\right\}(\Omega=\dot\omega\tau_k(\vec r_S)T_s)
\end{align}

% \subsection{MUSIC}
% The Multiple Signal Classification (MUSIC) algorithm can also be used to estimate the locational reflectivity of a scene.
% It operates on the time-domain fourier transform of the IF-signal, and makes similar far-field approximations as the DFT-based approach.
% The abstract signal model for MUSIC is:
% \begin{align}
%     \mathbf y(t) = \mathbf A \cdot \mathbf s(t) + \mathbf n(t)
% \end{align}
% Here, $\mathbf y,\mathbf n \in \mathbb{C}^{K}$,
% $\mathbf A \in \mathbb{C}^{K \times Z}$, and
% $\mathbf s \in \mathbb{C}^{Z}$.
% $Z$ is the number of voxels in the output image and $K$ the number of receive channels.
% For example, if the output image consist of $X \times Y \times Z$ cuboid voxels, then $Z=X\cdot Y\cdot Z$. \\
% Thus, the support matrix $\mathbf A$ is a linear transform from the locational reflectivity $\mathbf{s}$
% to the expected input signal vector $\mathbf{y}$.
% Each collumn vector $\mathbf a_z$ of the support matrix $\mathbf A$ therefor corresponds to the expected input signal vector caused by a point source. \\

% The MUSIC algorithm revolves around the correlation matrix of its input signal $\mathbf{R_{yy}}$.
% Assuming the a stationary scene with zero-mean noise of covariance $\mathbf{C_{nn}}$,
% it follows that
% \begin{align}
%     \mathbf{R_{yy}} & = \text{E}\{\mathbf{yy}^H\}             \\
%                     & =\mathbf{AR_{ss}A}^H + \mathbf{C_{nn}},
%     \text{\,with\,} \mathbf{R_{ss}} := \text{E}\{\mathbf{ss}^H\}
% \end{align}
% Assume that $\mathbf{R_{ss}}$ is nonsingular with rank $q$ and that $\mathbf{A}$ has full rank.
% If $\mathbf{R_{yy}}$ has $p$ eigenvalues, then the smallest $p-q$ of them are all $\sigma^2$,
% and their corresponding eigenvectors -- i.e. the collumns of $\mathbf{C_{nn}}$ -- are all orthogonal to the support vectors $\mathbf a_z$.

% This property is key to the MUSIC algorithm.
% The metric used to generate an image is the projection of $\mathbf a_z$ onto the $\mathbf{C_{nn}}$.
% Due to their orthogonality, the projection of support vectors corresponding to a signal source will be zero.
% The image intensity at voxel $z$ is thus defined computed as the normalized inverse square magnitude of this projection:

% \begin{align}
%     P_{MUSIC}[z] = \frac{\mathbf{a}_z^H \mathbf{a}_z}{\mathbf{a}_z^H\hat C_{nn}^H\hat C_{nn}\mathbf{a}_z}
% \end{align} \\

% The input signals are often highly correlated, due to phenomena such as multipath propagation or inter-channel crosstalk.
% This unfortunately means that nonsingularity of $\mathbf{R_{ss}}$ cannot always be guaranteed.
% A preprocessing step is required to ``decorrelate'' the signals and thereby making $\mathbf{R_{ss}}$ singular again.

% While early schemes, such as the ``3/4in plywood'' spacial dither algorithm by Widrow \textit{et al.} [CITE]
% consisted of mechanically moving the receive antenna array orthogonal to the look direction,
% preprocessing can also be done after receiving the signal.

% Spacial smoothing, as proposed by [CITE], improves the correlation matrix's eigenstructure by
